// AI service configuration for contract analysis and generation
import { deepseek } from "@ai-sdk/deepseek"
import { openai } from "@ai-sdk/openai"
import { generateText, streamText } from "ai"

// AI æœåŠ¡é…ç½®
interface AIConfig {
  provider: "deepseek" | "openai"
  model: string
  client: any
}

// è·å– AI é…ç½®
function getAIConfig(): AIConfig {
  // ä¼˜å…ˆä½¿ç”¨ DeepSeek
  if (process.env.DEEPSEEK_API_KEY) {
    return {
      provider: "deepseek",
      model: "deepseek-chat",
      client: deepseek('deepseek-chat'),
    }
  }

  // å›é€€åˆ° OpenAI
  if (process.env.OPENAI_API_KEY) {
    return {
      provider: "openai",
      model: "gpt-4o",
      client: openai('gpt-4o'),
    }
  }

  throw new Error("No AI API key configured. Please set DEEPSEEK_API_KEY or OPENAI_API_KEY")
}

export class AIContractService {
  static async analyzeContract(contractContent: string) {
    try {
      const config = getAIConfig()

      const { text } = await generateText({
        model: config.client(config.model),
        prompt: `ä½œä¸ºä¸“ä¸šçš„æ³•å¾‹AIåŠ©æ‰‹ï¼Œè¯·åˆ†æä»¥ä¸‹åˆåŒå†…å®¹ï¼Œå¹¶æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼š

åˆåŒå†…å®¹ï¼š
${contractContent}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æä¾›åˆ†æï¼š

## ğŸ“‹ åˆåŒåŸºæœ¬ä¿¡æ¯
- åˆåŒç±»å‹ï¼š
- åˆåŒä¸»é¢˜ï¼š
- æ¶‰åŠæ–¹æ•°é‡ï¼š

## ğŸ” å…³é”®æ¡æ¬¾åˆ†æ
1. **æ ¸å¿ƒæ¡æ¬¾**ï¼š
2. **æƒåˆ©ä¹‰åŠ¡**ï¼š
3. **ä»˜æ¬¾æ¡æ¬¾**ï¼š
4. **æ—¶é—´å®‰æ’**ï¼š

## âš ï¸ é£é™©ç‚¹è¯†åˆ«
1. **é«˜é£é™©æ¡æ¬¾**ï¼š
2. **æ¨¡ç³Šè¡¨è¿°**ï¼š
3. **ç¼ºå¤±æ¡æ¬¾**ï¼š

## ğŸ’° è´¢åŠ¡æ¡æ¬¾
- åˆåŒé‡‘é¢ï¼š
- ä»˜æ¬¾æ–¹å¼ï¼š
- è¿çº¦é‡‘æ¡æ¬¾ï¼š

## ğŸ“… é‡è¦æ—¥æœŸ
- åˆåŒæœŸé™ï¼š
- å…³é”®èŠ‚ç‚¹ï¼š

## ğŸ’¡ å»ºè®®å’Œæ”¹è¿›
1. **æ¡æ¬¾ä¼˜åŒ–å»ºè®®**ï¼š
2. **é£é™©é˜²èŒƒæªæ–½**ï¼š
3. **åˆè§„æ€§å»ºè®®**ï¼š

## ğŸ“Š åˆåŒè¯„åˆ†
- å®Œæ•´æ€§ï¼š/10
- æ¸…æ™°åº¦ï¼š/10
- é£é™©æ§åˆ¶ï¼š/10
- æ€»ä½“è¯„åˆ†ï¼š/10

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œç¡®ä¿åˆ†æä¸“ä¸šã€å‡†ç¡®ã€å®ç”¨ã€‚`,
        maxTokens: 2000,
        temperature: 0.7,
      })

      return {
        success: true,
        analysis: text,
        provider: config.provider,
        model: config.model,
      }
    } catch (error) {
      console.error("AI analysis error:", error)
      return {
        success: false,
        error: this.getErrorMessage(error),
      }
    }
  }

  static async generateContract(contractType: string, requirements: string) {
    try {
      const config = getAIConfig()

      const { text } = await generateText({
        model: config.client(config.model),
        prompt: `ä½œä¸ºä¸“ä¸šçš„æ³•å¾‹AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆä¸€ä»½å®Œæ•´çš„${contractType}ï¼š

éœ€æ±‚æè¿°ï¼š
${requirements}

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šã€å®Œæ•´çš„åˆåŒï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

# ${contractType}

## åˆåŒç¼–å·
[åˆåŒç¼–å·ï¼šå¾…å¡«å†™]

## ç”²æ–¹ï¼ˆå§”æ‰˜æ–¹/ä¹°æ–¹ï¼‰
- å…¬å¸åç§°ï¼š[ç”²æ–¹å…¬å¸åç§°]
- æ³•å®šä»£è¡¨äººï¼š[æ³•å®šä»£è¡¨äººå§“å]
- åœ°å€ï¼š[è¯¦ç»†åœ°å€]
- è”ç³»ç”µè¯ï¼š[è”ç³»ç”µè¯]
- é‚®ç®±ï¼š[é‚®ç®±åœ°å€]

## ä¹™æ–¹ï¼ˆæœåŠ¡æ–¹/å–æ–¹ï¼‰
- å…¬å¸åç§°ï¼š[ä¹™æ–¹å…¬å¸åç§°]
- æ³•å®šä»£è¡¨äººï¼š[æ³•å®šä»£è¡¨äººå§“å]
- åœ°å€ï¼š[è¯¦ç»†åœ°å€]
- è”ç³»ç”µè¯ï¼š[è”ç³»ç”µè¯]
- é‚®ç®±ï¼š[é‚®ç®±åœ°å€]

## ç¬¬ä¸€æ¡ åˆåŒç›®çš„å’Œä¾æ®
[åˆåŒç­¾ç½²çš„ç›®çš„å’Œæ³•å¾‹ä¾æ®]

## ç¬¬äºŒæ¡ æœåŠ¡å†…å®¹/å•†å“æè¿°
[è¯¦ç»†çš„æœåŠ¡å†…å®¹æˆ–å•†å“æè¿°]

## ç¬¬ä¸‰æ¡ åˆåŒé‡‘é¢å’Œä»˜æ¬¾æ–¹å¼
[å…·ä½“é‡‘é¢å’Œä»˜æ¬¾å®‰æ’]

## ç¬¬å››æ¡ å±¥è¡ŒæœŸé™å’Œåœ°ç‚¹
[æ—¶é—´å®‰æ’å’Œå±¥è¡Œåœ°ç‚¹]

## ç¬¬äº”æ¡ åŒæ–¹æƒåˆ©å’Œä¹‰åŠ¡
### ç”²æ–¹æƒåˆ©å’Œä¹‰åŠ¡ï¼š
### ä¹™æ–¹æƒåˆ©å’Œä¹‰åŠ¡ï¼š

## ç¬¬å…­æ¡ è´¨é‡æ ‡å‡†å’ŒéªŒæ”¶
[è´¨é‡è¦æ±‚å’ŒéªŒæ”¶æ ‡å‡†]

## ç¬¬ä¸ƒæ¡ è¿çº¦è´£ä»»
[è¿çº¦æƒ…å½¢å’Œè´£ä»»æ‰¿æ‹…]

## ç¬¬å…«æ¡ çŸ¥è¯†äº§æƒ
[çŸ¥è¯†äº§æƒå½’å±å’Œä¿æŠ¤]

## ç¬¬ä¹æ¡ ä¿å¯†æ¡æ¬¾
[ä¿å¯†ä¹‰åŠ¡å’ŒèŒƒå›´]

## ç¬¬åæ¡ äº‰è®®è§£å†³
[äº‰è®®è§£å†³æ–¹å¼]

## ç¬¬åä¸€æ¡ åˆåŒå˜æ›´å’Œè§£é™¤
[å˜æ›´å’Œè§£é™¤æ¡ä»¶]

## ç¬¬åäºŒæ¡ å…¶ä»–çº¦å®š
[å…¶ä»–ç‰¹æ®Šçº¦å®š]

## ç¬¬åä¸‰æ¡ åˆåŒç”Ÿæ•ˆ
æœ¬åˆåŒè‡ªåŒæ–¹ç­¾å­—ç›–ç« ä¹‹æ—¥èµ·ç”Ÿæ•ˆï¼Œæœ‰æ•ˆæœŸè‡³[ç»“æŸæ—¥æœŸ]ã€‚

## ç­¾ç½²
ç”²æ–¹ï¼ˆç›–ç« ï¼‰ï¼š________________    ä¹™æ–¹ï¼ˆç›–ç« ï¼‰ï¼š________________
æ³•å®šä»£è¡¨äººï¼š__________________    æ³•å®šä»£è¡¨äººï¼š__________________
ç­¾ç½²æ—¥æœŸï¼š____________________    ç­¾ç½²æ—¥æœŸï¼š____________________

è¯·ç¡®ä¿åˆåŒå†…å®¹ä¸“ä¸šã€å®Œæ•´ã€ç¬¦åˆæ³•å¾‹è§„èŒƒï¼Œå¹¶æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–è°ƒæ•´ã€‚`,
        maxTokens: 3000,
        temperature: 0.7,
      })

      return {
        success: true,
        contract: text,
        provider: config.provider,
        model: config.model,
      }
    } catch (error) {
      console.error("Contract generation error:", error)
      return {
        success: false,
        error: this.getErrorMessage(error),
      }
    }
  }

  static async streamContractGeneration(contractType: string, requirements: string) {
    const config = getAIConfig()

    return streamText({
      model: config.client(config.model),
      prompt: `æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆä¸€ä»½${contractType}åˆåŒæ¨¡æ¿ï¼š

è¦æ±‚ï¼š
${requirements}

è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„åˆåŒæ¨¡æ¿ï¼Œé€æ­¥è¾“å‡ºå†…å®¹ã€‚`,
      maxTokens: 3000,
      temperature: 0.7,
    })
  }

  static async testConnection(customPrompt?: string) {
    try {
      const config = getAIConfig()
      const prompt = customPrompt || "è¯·ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½åœ¨åˆåŒç®¡ç†ä¸­çš„åº”ç”¨ã€‚"

      const { text } = await generateText({
        model: config.client(config.model),
        prompt,
        maxTokens: 150,
        temperature: 0.7,
      })

      return {
        success: true,
        result: text,
        provider: config.provider,
        model: config.model,
      }
    } catch (error) {
      console.error("AI test error:", error)
      return {
        success: false,
        error: this.getErrorMessage(error),
      }
    }
  }

  static async performanceTest() {
    try {
      const config = getAIConfig()
      const startTime = Date.now()

      const testPrompts = ["è¯·ç®€è¿°åˆåŒçš„åŸºæœ¬è¦ç´ ã€‚", "ä»€ä¹ˆæ˜¯è¿çº¦è´£ä»»ï¼Ÿ", "å¦‚ä½•ç¡®ä¿åˆåŒçš„æ³•å¾‹æ•ˆåŠ›ï¼Ÿ"]

      const results = []

      for (const prompt of testPrompts) {
        const testStart = Date.now()

        const { text } = await generateText({
          model: config.client(config.model),
          prompt,
          maxTokens: 100,
          temperature: 0.7,
        })

        const testEnd = Date.now()

        results.push({
          prompt,
          response: text,
          responseTime: testEnd - testStart,
        })
      }

      const totalTime = Date.now() - startTime

      return {
        success: true,
        provider: config.provider,
        model: config.model,
        totalTime,
        averageTime: totalTime / testPrompts.length,
        results,
      }
    } catch (error) {
      console.error("Performance test error:", error)
      return {
        success: false,
        error: this.getErrorMessage(error),
      }
    }
  }

  static getAIInfo() {
    try {
      const config = getAIConfig()
      return {
        available: true,
        provider: config.provider,
        model: config.model,
        sdkVersion: config.provider === "deepseek" ? "@ai-sdk/deepseek" : "@ai-sdk/openai",
      }
    } catch (error) {
      return {
        available: false,
        provider: "none",
        model: "N/A",
        error: this.getErrorMessage(error),
      }
    }
  }

  private static getErrorMessage(error: any): string {
    if (error instanceof Error) {
      if (error.message.includes("API key")) {
        return "AI API å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"
      }
      if (error.message.includes("quota")) {
        return "AI API é…é¢å·²ç”¨å®Œï¼Œè¯·æ£€æŸ¥è´¦æˆ·ä½™é¢"
      }
      if (error.message.includes("rate limit")) {
        return "è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
      }
      if (error.message.includes("No AI API key")) {
        return "æœªé…ç½® AI API å¯†é’¥ï¼Œè¯·è®¾ç½® DEEPSEEK_API_KEY æˆ– OPENAI_API_KEY"
      }
      return error.message
    }
    return "AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
  }
}
